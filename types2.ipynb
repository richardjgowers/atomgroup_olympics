{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import atomtypes2 as atomtypes\n",
    "import MDAnalysis as mda\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "u = mda.Universe('big.gro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oldag = u.atoms\n",
    "master = atomtypes.convert(u.atoms)\n",
    "\n",
    "# The size of AtomGroup to test\n",
    "natoms = 250000\n",
    "idx = np.random.randint(0, len(u.atoms), natoms)\n",
    "\n",
    "oldag = u.atoms[idx]\n",
    "newag = master[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "oldag_full = u.atoms\n",
    "newag_full = atomtypes.convert(u.atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# since the processor cache will affect the speeds of repeated access,\n",
    "# we want to take only the cached calls and leave off the slow ones for our\n",
    "# timing runs so we can at least compare consistently\n",
    "percentile = .75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let the games begin "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get some attributes\n",
    "\n",
    "Fetch the names for our atomgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 50: 7.57 ms per loop\n",
      "1 loops, best of 50: 173 ms per loop\n",
      "New style took: 0.00763145652977\n",
      "Old style took: 0.174694370579\n",
      "\n",
      "Speed up of new: 22.8913536882\n"
     ]
    }
   ],
   "source": [
    "a_new = %timeit -n1 -r50 -o newag.names()\n",
    "s_new = pd.Series(a_new.all_runs)\n",
    "t_new = s_new[s_new < s_new.quantile(percentile)].mean()\n",
    "\n",
    "a_old = %timeit -n1 -r50 -o oldag.names()\n",
    "s_old = pd.Series(a_old.all_runs)\n",
    "t_old = s_old[s_old < s_old.quantile(percentile)].mean()\n",
    "\n",
    "print \"New style took: {}\".format(t_new)\n",
    "print \"Old style took: {}\".format(t_old)\n",
    "print \"\"\n",
    "print \"Speed up of new: {}\".format(t_old / t_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetch the charges for our atomgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 50: 4.96 ms per loop\n",
      "1 loops, best of 50: 74.7 ms per loop\n",
      "New style took: 0.00501285372554\n",
      "Old style took: 0.0753132394842\n",
      "\n",
      "Speed up of new: 15.0240249582\n"
     ]
    }
   ],
   "source": [
    "a_new = %timeit -n1 -r50 -o newag.charges()\n",
    "s_new = pd.Series(a_new.all_runs)\n",
    "t_new = s_new[s_new < s_new.quantile(percentile)].mean()\n",
    "\n",
    "a_old = %timeit -n1 -r50 -o oldag.charges()\n",
    "s_old = pd.Series(a_old.all_runs)\n",
    "t_old = s_old[s_old < s_old.quantile(percentile)].mean()\n",
    "\n",
    "print \"New style took: {}\".format(t_new)\n",
    "print \"Old style took: {}\".format(t_old)\n",
    "print \"\"\n",
    "print \"Speed up of new: {}\".format(t_old / t_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's set some attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 50: 3.99 ms per loop\n",
      "1 loops, best of 50: 151 ms per loop\n",
      "New style took: 0.00402729575698\n",
      "Old style took: 0.158945309149\n",
      "\n",
      "Speed up of new: 39.4670068305\n"
     ]
    }
   ],
   "source": [
    "charges = np.random.random(len(oldag))\n",
    "\n",
    "a_new = %timeit -n1 -r50 -o newag.set_charges(charges)\n",
    "s_new = pd.Series(a_new.all_runs)\n",
    "t_new = s_new[s_new < s_new.quantile(percentile)].mean()\n",
    "\n",
    "a_old = %timeit -n1 -r50 -o oldag.set_charge(charges)\n",
    "s_old = pd.Series(a_old.all_runs)\n",
    "t_old = s_old[s_old < s_old.quantile(percentile)].mean()\n",
    "\n",
    "print \"New style took: {}\".format(t_new)\n",
    "print \"Old style took: {}\".format(t_old)\n",
    "print \"\"\n",
    "print \"Speed up of new: {}\".format(t_old / t_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try some fancy indexing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 9.00 times longer than the fastest. This could mean that an intermediate result is being cached \n",
      "1 loops, best of 50: 102 Âµs per loop\n",
      "1 loops, best of 50: 5.79 ms per loop\n",
      "New style took: 0.000199026531643\n",
      "Old style took: 0.00595336347013\n",
      "\n",
      "Speed up of new: 29.9124112799\n"
     ]
    }
   ],
   "source": [
    "idx2 = np.random.randint(0, len(oldag), size=25000)\n",
    "\n",
    "a_new = %timeit -n1 -r50 -o newag[idx2]\n",
    "s_new = pd.Series(a_new.all_runs)\n",
    "t_new = s_new[s_new < s_new.quantile(percentile)].mean()\n",
    "\n",
    "a_old = %timeit -n1 -r50 -o oldag[idx2]\n",
    "s_old = pd.Series(a_old.all_runs)\n",
    "t_old = s_old[s_old < s_old.quantile(percentile)].mean()\n",
    "\n",
    "print \"New style took: {}\".format(t_new)\n",
    "print \"Old style took: {}\".format(t_old)\n",
    "print \"\"\n",
    "print \"Speed up of new: {}\".format(t_old / t_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about fancy indexing the full set of atoms? Does the relative speedup depend on system size?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 50: 1.05 ms per loop\n",
      "1 loops, best of 50: 22.7 ms per loop\n",
      "New style took: 0.00110406488986\n",
      "Old style took: 0.0233755240569\n",
      "\n",
      "Speed up of new: 21.1722374941\n"
     ]
    }
   ],
   "source": [
    "idx2 = np.random.randint(0, len(oldag_full), size=25000)\n",
    "\n",
    "a_new = %timeit -n1 -r50 -o newag_full[idx2].names()\n",
    "s_new = pd.Series(a_new.all_runs)\n",
    "t_new = s_new[s_new < s_new.quantile(percentile)].mean()\n",
    "\n",
    "a_old = %timeit -n1 -r50 -o oldag_full[idx2].names()\n",
    "s_old = pd.Series(a_old.all_runs)\n",
    "t_old = s_old[s_old < s_old.quantile(percentile)].mean()\n",
    "\n",
    "print \"New style took: {}\".format(t_new)\n",
    "print \"Old style took: {}\".format(t_old)\n",
    "print \"\"\n",
    "print \"Speed up of new: {}\".format(t_old / t_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making selections based on names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pull out all atoms called 'OW' from the atomgroup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loops, best of 50: 12.6 ms per loop\n",
      "1 loops, best of 50: 198 ms per loop\n",
      "New style took :0.0126413976824\n",
      "Old style took :0.198858480196\n",
      "\n",
      "Speed up of new: 15.7307352551\n"
     ]
    }
   ],
   "source": [
    "a_new = %timeit -n1 -r50 -o newag[newag.names() == 'OW']\n",
    "s_new = pd.Series(a_new.all_runs)\n",
    "t_new = s_new[s_new < s_new.quantile(percentile)].mean()\n",
    "\n",
    "a_old = %timeit -n1 -r50 -o oldag[oldag.names() == 'OW']\n",
    "s_old = pd.Series(a_old.all_runs)\n",
    "t_old = s_old[s_old < s_old.quantile(percentile)].mean()\n",
    "\n",
    "print \"New style took :{}\".format(t_new)\n",
    "print \"Old style took :{}\".format(t_old)\n",
    "print \"\"\n",
    "print \"Speed up of new: {}\".format(t_old/t_new)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
